{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988c4ea4",
   "metadata": {},
   "source": [
    "# Film preperation using particle deposition.\n",
    "\n",
    "This tutorial demonstrates particle film generation using ballistic deposition.\n",
    "\n",
    "#### Current maintainer\n",
    "- Stefan Endres (s.endres@iwt.uni-bremen.de)\n",
    "\n",
    "#### Previous authors:     \n",
    "- Valentine Baric \n",
    "- Lutz Mädler$^*$ (lmaeder@iwt.uni-bremen.de)\n",
    "- Norbert Riefler \n",
    "\n",
    "#### Literature: \n",
    "##### Film generation primary sources:\n",
    "\n",
    "- Mädler et al. (2006), Nanotechnology 17, 3783-4795\n",
    "- Norbert, R. and Mädler. L. (2010) Journal of Nanoparticle Research 12.3 : 853-863.\n",
    "\n",
    "##### Secondary:\n",
    "\n",
    "- Filippov et al. (2000), Journal of Colloid and Interface Science 229, 261-273\n",
    "- Ermak and Buckholz (1980), Journal of Computational Physics 35. 169-182\n",
    "- Chan and Dahneke (1981), J. Appl. Phys. 52 3106-10"
   ]
  },
  {
   "cell_type": "code",
   "id": "89834caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:29.801015Z",
     "start_time": "2025-04-04T08:54:29.338777Z"
    }
   },
   "source": [
    "## Imports\n",
    "# Std. library\n",
    "import sys, random, os, datetime, warnings, socket, argparse\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "# Dependencies:\n",
    "from scipy import spatial, stats\n",
    "import shutil, fcntl, termios, struct\n",
    "# Local imports:\n",
    "from main_function import *\n",
    "import functions as f\n",
    "from create_aggregate import create_aggregate as SA\n",
    "from create_aggregate_CCA import create_aggregate as CCA\n",
    "import debugging as debug\n",
    "from classes_agg import Aggregate as Aggregate\n",
    "from classes_agg import Particle as Particle\n",
    "import write_output\n",
    "import terminal_print\n",
    "import statistics\n",
    "warnings.filterwarnings('error')\n",
    "if sys.stdout.isatty():\n",
    "    Redirection = 0\n",
    "    COLS = struct.unpack('hh',  fcntl.ioctl(sys.stdout, termios.TIOCGWINSZ, '1234'))[1] -1\n",
    "else:\n",
    "    COLS = 60\n",
    "    Redirection = 1"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f18f6920",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Next we import the parameters for the film generation, the `dda_template.py` file can be modified to add custom parameters, alteratively the desired imports can be modified in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5c1c70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:30.076256Z",
     "start_time": "2025-04-04T08:54:29.805580Z"
    }
   },
   "source": [
    "# The inputfile has to be copied to the folder of the source, otherwise it cannot be imported (shutil.copy2) (only if they are not already in the same folder)\n",
    "import dda_template as params\n",
    "source_file = os.getcwd()\n",
    "PID = os.getpid() \n",
    "params_file = 'dda_template.py'\n",
    "\n",
    "# Initiate parameters:\n",
    "init_params(params_file, source_file)\n",
    "# Example parameters that can be modified:\n",
    "params.N_tot = 2000#0000  # Maximum number of primary particles (PP)  (test with low number)\n",
    "params.experiment  # The name of this experiment\n",
    "params.output_folder  # Folder for output data\n",
    "params.T  # Gas temperature\n",
    "params.D_f  # Fractal dimension\n",
    "k_f = params.k_f  # Prefractor for D_f\n",
    "epsilon = params.epsilon  # Minimum distance between two PP\n",
    "delta = params.delta  # Maximum distance between two PP\n",
    "deformation = params.deformation  # Deformation factor\n",
    "params.rho  # Density of the particle\n",
    "params.dt  # Timestep\n",
    "Height_above = params.Height_above  # Initialization hight above the highest particle\n",
    "\n",
    "# Parrallelization:\n",
    "num_cores = 30  # Specify the number of CPUs used for parallel computing\n",
    "jobserver = mp.Pool(processes = num_cores)\n",
    "if num_cores == -1:\n",
    "    num_cores = mp.cpu_count()\n",
    "elif num_cores <= 0 or num_cores > mp.cpu_count():\n",
    "    num_cores = mp.cpu_count()\n",
    "    print(\"\"\"Invalid number of CPUs\n",
    "        ==> Maximum number of CPU used ('%i')\"\"\" %num_cores)\n",
    "    \n",
    "jobserver = mp.Pool(processes = num_cores)\n",
    "\n",
    "# Algorithmic controls:\n",
    "k_B = 1.3806488e-23         # Boltzmann-Constant in J/K\n",
    "start = datetime.datetime.now().replace(microsecond=0) # Starting time\n",
    "cwd = os.getcwd()           # Current directory\n",
    "RESTART = False\n",
    "random.seed(params.custom_seed_traj)  # set a new seed for random numbers"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Pool.__del__ at 0x787dcc487600>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endres/anaconda3/envs/ddg/lib/python3.11/multiprocessing/pool.py\", line 268, in __del__\n",
      "    _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=30>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "795d89d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:55:55.725249Z",
     "start_time": "2025-04-04T08:55:55.722578Z"
    }
   },
   "source": [
    "archive_folder = './archive'\n",
    "\n",
    "#current_date = now.strftime(\"%Y%m%d\")\n",
    "write_lammpstrj = output_trj(params)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.FileIO name='./dda/log.dda' mode='wb' closefd=True>\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_118694/1220664847.py\", line 4, in <module>\n",
      "ResourceWarning: unclosed file <_io.TextIOWrapper name='./dda/log.dda' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "6fbe0b20",
   "metadata": {},
   "source": [
    "# Film generation"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdd20042",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:33.756800Z",
     "start_time": "2025-04-04T08:54:30.155646Z"
    }
   },
   "source": [
    "results, aggs, N_PP_per_Agg = generate_film(params, source_file, num_cores, jobserver)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************\n",
      "Process data\n",
      "\tExperiment:\t\tdda\n",
      "\tStarting Time:\t\t2025-04-04 10:54\n",
      "\tPID:\t\t\t118694\n",
      "\tCPUs:\t\t\t30\n",
      "\n",
      "************************************************************\n",
      "System parameters\n",
      "\tPe:\t\t\t1.00e+00\n",
      "\tBox size:\t\t280\n",
      "\tPrimary Particles:\t2000\n",
      "\tCluster per Aggregate:\t6\n",
      "\tAggregates:\t\t65\n",
      "\tParticle Number Dist.:\tnone\n",
      "\tParticle Size Dist.:\tlognorm\n",
      "\tMedian radius (nm):\t4.479e+00\n",
      "\tSigma:\t\t\t3.700e-01\n",
      "\tNeighbor Mode:\t\t2\n",
      "\tFriction Model:\tChan&Dahneke\n",
      "\n",
      "************************************************************\n",
      "Modules\n",
      "\tCalculate Coordination (2)\n",
      "\t\tThreshold: Delta (2)\n",
      "\tCalculate Percolation (3)\n",
      "\t\tThreshold: One rp (1)\n",
      "\n",
      "************************************************************\n",
      "Outputfiles\n",
      "\tDefault outputdata\n",
      "\tlog file (1)\n",
      "\tLIGGGHTS hybrid granular/molecular data file (2)\n",
      "\tLIGGGHTS granular data file (3)\n",
      "\tVTK Output for paraview (5)\n",
      "\tHistogram with primary particle size distibution (7)\n",
      "\tHistogram with primary particle number distibution (8)\n",
      "\n",
      "************************************************************\n",
      "Debugging routines:\n",
      "\tCalculate overlapping particles with boundaries (4)\n",
      "\n",
      "************************************************************\n",
      "\n",
      "##### Aggregate generation initiated\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "72de6706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:33.772250Z",
     "start_time": "2025-04-04T08:54:33.766623Z"
    }
   },
   "source": [
    "pt, maximal_radius = global_pp_indexing(aggs)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "19f02976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:33.937950Z",
     "start_time": "2025-04-04T08:54:33.810295Z"
    }
   },
   "source": [
    "write_output.N_histogram(N_PP_per_Agg, params.output_folder, params.experiment, params)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "1a5755ab",
   "metadata": {},
   "source": [
    "# Particle Transport\n",
    "At first the velocity is calculated according to the Langevin\n",
    "equation of motion. This equation is solved according to Ermak and\n",
    "Buckholz, 1980 with a random fluctuating force (B1/B2) and an applied force\n",
    "(only relevant for the z-direction (force_z)). According to this velocity\n",
    "the displacement is calculated and the aggregate is moved. Each timestep (v)\n",
    "is computed on basis of the previous step (v0)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4c0e216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:33.999529Z",
     "start_time": "2025-04-04T08:54:33.942195Z"
    }
   },
   "source": [
    "max_z = particle_transport(aggs, pt, params, maximal_radius, write_lammpstrj)\n",
    "#max_z ="
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Particle Transport calculation initiated\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "62228952",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1ed4fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:34.022162Z",
     "start_time": "2025-04-04T08:54:34.005262Z"
    }
   },
   "source": [
    "write_lammpstrj.close()  # Note, if you want to re-run the cells above this needs to be re-opened\n",
    "\n",
    "# Generate .trj and .vtk files in the output_folder    \n",
    "post_proc(params, pt, aggs, source_file, max_z)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "be491f48",
   "metadata": {},
   "source": [
    "# Film properties and visualisations\n",
    "\n",
    "In the `functions.py` file functions for computing the film `packing_density`, `coordination` number and `percolation` of the film are found. The `.trj` and `.vtk` files can be visualised. The cell below allows for visualisation of the particle film using polyscope which can be downloaded easily from PyPi using `$ pip install polyscope`:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ecf4b9ab",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:34.207031Z",
     "start_time": "2025-04-04T08:54:34.048842Z"
    }
   },
   "source": [
    "from classes.particlelayer import *\n",
    "import numpy as np\n",
    "import json\n",
    "import polyscope as ps\n",
    "\n",
    "file  = './dda/dda.trj'\n",
    "layer = particlelayer(file, nodescription=False).layer\n",
    "\n",
    "# Shape\n",
    "layer._data.shape\n",
    "\n",
    "# Extract positions in space\n",
    "points = np.zeros([layer.data.shape[0], 3])\n",
    "points[:, 0] = layer.data[:, layer.lib['x']]\n",
    "points[:, 1] = layer.data[:, layer.lib['y']]\n",
    "points[:, 2] = layer.data[:, layer.lib['z']]\n",
    "\n",
    "# Extract the radius\n",
    "radii  = np.zeros(layer.data.shape[0])\n",
    "radii = layer.data[:, layer.lib['r']]\n",
    "\n",
    "# Plot in polyscope\n",
    "ps.init()\n",
    "ps.set_up_dir(\"z_up\")\n",
    "ps_cloud = ps.register_point_cloud(\"Particles\", points)\n",
    "ps_cloud.add_scalar_quantity(\"Particle radii\", radii)\n",
    "ps_cloud.set_point_radius_quantity(\"Particle radii\", autoscale=False)\n",
    "ps_cloud.set_color((1.0, 1.0, 1.0))\n",
    "ps.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Reading Particle Structure File\n",
      "# Filename: ./case_studies/hetero/results/dda.trj\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './case_studies/hetero/results/dda.trj'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpolyscope\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mps\u001B[39;00m\n\u001B[1;32m      6\u001B[0m file  \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./case_studies/hetero/results/dda.trj\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 7\u001B[0m layer \u001B[38;5;241m=\u001B[39m \u001B[43mparticlelayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnodescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlayer\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Shape\u001B[39;00m\n\u001B[1;32m     10\u001B[0m layer\u001B[38;5;241m.\u001B[39m_data\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/projects/film_deposition/classes/particlelayer.py:15\u001B[0m, in \u001B[0;36mparticlelayer.__init__\u001B[0;34m(self, inputfile, nodescription)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lib \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrj\u001B[39m\u001B[38;5;124m'\u001B[39m: layer_trj, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvtk\u001B[39m\u001B[38;5;124m'\u001B[39m: layer_vtk, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatafile\u001B[39m\u001B[38;5;124m'\u001B[39m: layer_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msingleAggregate\u001B[39m\u001B[38;5;124m'\u001B[39m: singleAggregate}\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nodescription:\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprintInfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/film_deposition/classes/particlelayer.py:64\u001B[0m, in \u001B[0;36mparticlelayer.printInfo\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m# Filename: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile))\n\u001B[1;32m     63\u001B[0m string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 64\u001B[0m string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m# File Format: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m))\n\u001B[1;32m     65\u001B[0m string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# Units: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer\u001B[38;5;241m.\u001B[39munits))\n\u001B[1;32m     66\u001B[0m string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# Primary Particles: \u001B[39m\u001B[38;5;132;01m{:,}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer\u001B[38;5;241m.\u001B[39mparticles))\n",
      "File \u001B[0;32m~/projects/film_deposition/classes/particlelayer.py:30\u001B[0m, in \u001B[0;36mparticlelayer.format\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 30\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetFormat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format\n",
      "File \u001B[0;32m~/projects/film_deposition/classes/particlelayer.py:42\u001B[0m, in \u001B[0;36mparticlelayer.getFormat\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvtk\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrj\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdump\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile:\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     43\u001B[0m         lines \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreadlines()\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mITEM:\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m lines[\u001B[38;5;241m0\u001B[39m]:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './case_studies/hetero/results/dda.trj'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7f231224",
   "metadata": {},
   "source": [
    "Explanation of main classes and functions:\n",
    "#### AGGREGATE-CLASS\n",
    "    \n",
    "    Additional to this main program there are some more module files:\n",
    "    Whenever a property of an aggregate is needed you will see something like:\n",
    "    aggs[k].r\n",
    "    This means that in aggs there are all aggregates stored and \"k\" is the\n",
    "    index of the aggregate. \".r\" is the property of the aggregate, in this case\n",
    "    r shows all the radii of the PP within this aggregate.\n",
    "    All properties and functions which start like this (aggs[k].) are found in classes.py\n",
    "\n",
    "#### PARTICLE-CLASS\n",
    "    \n",
    "    Same as above for AGGREGATE. The abbreviation is pt[k]. It is also found in classes.py\n",
    "\n",
    "#### FUNCTIONS\n",
    "    \n",
    "    Functions which are not specific for one aggregate are in the document functions.py\n",
    "    So if there is a function like \"f.rank_z()\" you'll find it there."
   ]
  },
  {
   "cell_type": "code",
   "id": "0f31482d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:34.209339107Z",
     "start_time": "2025-03-14T13:24:03.132175Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
